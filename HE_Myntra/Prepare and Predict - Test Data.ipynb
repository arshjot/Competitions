{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "import cv2\n",
    "import h5py\n",
    "import imutils\n",
    "import glob\n",
    "import os\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Activation\n",
    "from keras.layers import UpSampling2D, BatchNormalization, Flatten, Dense, GlobalMaxPooling2D\n",
    "from keras.layers.core import Dropout, Reshape\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./Data/Share/myntra_train_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('./Data/Share/Submission_offline3d61f7e.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 62/14752 [02:11<111:54:07, 27.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://repo.karvyecom.com/image-repository/Classic/PERLE-CTS/PERLE-CTS_1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 186/14752 [02:11<54:22:31, 13.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://cdn.myeshopbox.com/flipkart_images/duke-75-styles-18lot/SDVP10Q_Ambrosia/COMBO_1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 562/14752 [02:11<18:10:22,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://images.myeshopbox.com/Duke_18_Styles/Duke_18_Styles/BBAPLDK31571/MYNTRA_2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 618/14752 [04:22<11:46:45,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://repo.karvyecom.com/image-repository/Classic/PERLE-STB/PERLE-STB_1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 830/14752 [04:22<3:59:07,  1.03s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://cdn.myeshopbox.com/flipkart_images/duke-45-styles-lot24/LF2499_Sky/FLIPKART_2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1027/14752 [06:33<2:47:51,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://repo.karvyecom.com/image-repository/Classic/4-SEASONVA-106/4-SEASONVA-106_1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 1420/14752 [06:33<1:20:06,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://cdn.myeshopbox.com/flipkart_images/duke-45-styles-lot24/LF2499_Lemon/FLIPKART_2.jpg\n",
      "http://cdn.myeshopbox.com/flipkart_images/duke-101-style/SD23_Cranberry/MYNTRA_2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 1550/14752 [06:33<55:36,  3.96it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://myntra.myntassets.com/assets/images/1897348/2017/5/10/11494413157851-Duke-Men-Tshirts-5921494413157651-1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 2017/14752 [08:44<55:19,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://repo.karvyecom.com/image-repository/Classic/4-SEASONVA-116/4-SEASONVA-116_1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 2041/14752 [08:44<39:23,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://cdn.myeshopbox.com/flipkart_images/duke-45-styles-lot24/LF2673_Coral/FLIPKART_2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 2341/14752 [10:55<53:58,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://repo.karvyecom.com/image-repository/Classic/PERLE-RBR/PERLE-RBR_1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█▉        | 2950/14752 [10:55<35:58,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://cdn.myeshopbox.com/flipkart_images/Duke-36-mix-lot-images/BBAPLDK34349/FLIPKART_2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 3631/14752 [10:56<16:41, 11.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://cdn.myeshopbox.com/flipkart_images/Duke-36-mix-lot-images/BBAPLDK34336/FLIPKART_2.jpg\n",
      "http://cdn.myeshopbox.com/flipkart_images/Duke-36-mix-lot-images/BBAPLDK34374/FLIPKART_2.jpg\n",
      "http://images.myeshopbox.com/Duke_18_Styles/Duke_18_Styles/BBAPLDK31612/MYNTRA_0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 4513/14752 [10:56<10:46, 15.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://cdn.myeshopbox.com/flipkart_images/Duke-36-mix-lot-images/BBAPLDK33598/FLIPKART_2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 4982/14752 [13:06<24:42,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://repo.karvyecom.com/image-repository/Classic/C-4-SEASONVA-110/C-4-SEASONVA-110_1.jpg\n",
      "http://cdn.myeshopbox.com/flipkart_images/Duke-36-mix-lot-images/BBAPLDK34348/FLIPKART_2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 5147/14752 [13:06<12:05, 13.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://cdn.myeshopbox.com/flipkart_images/Duke-36-mix-lot-images/BBAPLDK31546/FLIPKART_2.jpg\n",
      "http://cdn.myeshopbox.com/flipkart_images/Duke-36-mix-lot-images/BBAPLDK34344/FLIPKART_2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 5470/14752 [15:17<5:32:07,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://repo.karvyecom.com/image-repository/Classic/PERLE-BLK/PERLE-BLK_1.jpg\n",
      "http://cdn.myeshopbox.com/flipkart_images/duke-45-styles-lot24/LF2663_D.Navy/FLIPKART_2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 6009/14752 [17:28<2:50:04,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://repo.karvyecom.com/image-repository/Classic/PERLE-NVY/PERLE-NVY_1.jpg\n",
      "http://cdn.myeshopbox.com/flipkart_images/duke-45-styles-lot24/LF2780_L.Navy/FLIPKART_2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▍     | 6599/14752 [17:28<1:51:01,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://cdn.myeshopbox.com/flipkart_images/duke-45-styles-lot24/SD21_Anthra/FLIPKART_2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 7312/14752 [19:39<1:17:44,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://repo.karvyecom.com/image-repository/Classic/PERLE-SLT/PERLE-SLT_1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▎    | 7904/14752 [19:39<50:06,  2.28it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://cdn.myeshopbox.com/flipkart_images/duke-45-styles-lot24/LF2775_L.Navy/FLIPKART_2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 8216/14752 [19:40<23:30,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://cdn.myeshopbox.com/flipkart_images/duke-45-styles-lot24/LF2661_Cherry%20Tomato/FLIPKART_2.jpg\n",
      "http://cdn.myeshopbox.com/flipkart_images/duke-101-style/SDVP10Q_Sirocco/COmbo%20_1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 8552/14752 [19:40<15:40,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://dl.dropboxusercontent.com/sh/58h8ygy8hl75jad/AABz2a3hZsn5bRIdLlBOXS4ia/CATWTSAILJ6B1_1.jpg?dl=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 9403/14752 [21:50<10:03,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://repo.karvyecom.com/image-repository/Classic/PERLE-DSL/PERLE-DSL_1.jpg\n",
      "http://images.myeshopbox.com/Duke_18_Styles/Duke_18_Styles/BBAPLDK31621/MYNTRA_0.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 10333/14752 [21:51<04:05, 18.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://cdn.myeshopbox.com/flipkart_images/duke-45-styles-lot24/LF2775_Turquoise/FLIPKART_2.jpg\n",
      "http://cdn.myeshopbox.com/flipkart_images/Duke-36-mix-lot-images/BBAPLDK31561/FLIPKART_2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 11214/14752 [24:01<04:54, 12.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://repo.karvyecom.com/image-repository/Classic/C-4-SEASONVA-105/C-4-SEASONVA-105_1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 12173/14752 [24:02<01:49, 23.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://cdn.myeshopbox.com/flipkart_images/Duke-36-mix-lot-images/BBAPLDK34347/FLIPKART_2.jpg\n",
      "http://cdn.myeshopbox.com/flipkart_images/duke-45-styles-lot24/LF2633_Riviera/FLIPKART_2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 12511/14752 [26:12<05:25,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://repo.karvyecom.com/image-repository/Classic/C-4-SEASONVA-103/C-4-SEASONVA-103_1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 13333/14752 [26:13<01:41, 13.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://cdn.myeshopbox.com/flipkart_images/Duke-36-mix-lot-images/BBAPLDK34350/FLIPKART_2.jpg\n",
      "http://cdn.myeshopbox.com/flipkart_images/duke-45-styles-lot24/LF2778_Cranberry/FLIPKART_2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 14434/14752 [36:41<3:29:10, 39.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://repo.karvyecom.com/image-repository/Classic/C-4-SEASONVA-113/C-4-SEASONVA-113_1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14752/14752 [42:06<00:00,  1.14it/s]  \n"
     ]
    }
   ],
   "source": [
    "offline_test = pd.read_csv('./Data/Share/Submission_offline3d61f7e.csv')\n",
    "faulty_test_offline = []\n",
    "for url in tqdm(offline_test['Link_to_the_image'].dropna().drop_duplicates()):\n",
    "    name = url[url.rfind('/')+1:]\n",
    "    if os.path.exists('./Data/Test_offline/'+name):\n",
    "        continue\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, './Data/Test_offline/'+name)\n",
    "    except:\n",
    "        print(url)\n",
    "        faulty_test_offline.append(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract T-shirt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def boundingBox(edges, im):\n",
    "    gray = edges.astype('uint8')\n",
    "    im_h = gray.shape[0]\n",
    "    im_w = gray.shape[1]\n",
    "    cnts = cv2.findContours(gray,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if imutils.is_cv2() else cnts[1]\n",
    "     \n",
    "    x_l, y_l, x_r, y_r = [], [], [], []\n",
    "    \n",
    "    # loop over the digit area candidates\n",
    "    for c in cnts:\n",
    "        # compute the bounding box of the contour\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        \n",
    "        x_l.append(x)\n",
    "        y_l.append(y)\n",
    "        x_r.append(x+w)\n",
    "        y_r.append(y+h)\n",
    "        \n",
    "    \n",
    "    # Getting the outer most bounding box\n",
    "    x_l = min(x_l)\n",
    "    y_l = min(y_l)\n",
    "    x_r = max(x_r)\n",
    "    y_r = max(y_r)\n",
    "        \n",
    "    return im[y_l:y_r, x_l:x_r, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractTshirt(im):\n",
    "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    v = np.median(gray)\n",
    "    sigma = 0.33\n",
    "\n",
    "    #---- apply optimal Canny edge detection using the computed median----\n",
    "    lower_thresh = int(max(0, (1.0 - sigma) * v))\n",
    "    upper_thresh = int(min(255, (1.0 + sigma) * v))\n",
    "    edges = cv2.Canny(blur, lower_thresh, upper_thresh)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    dilated = cv2.morphologyEx(edges, cv2.MORPH_DILATE, kernel)\n",
    "    bounded = boundingBox(dilated, im)\n",
    "    if bounded.shape[0]<1250:\n",
    "        bounded = bounded\n",
    "    else:\n",
    "        height = bounded.shape[0]\n",
    "        width = bounded.shape[1]\n",
    "        bounded = bounded[int(1.3*height//4):int(3.5*(height//4)), :, :]\n",
    "    return bounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims_test = []\n",
    "for im_path in tqdm(glob.glob('./Data/Test_offline/*')):\n",
    "    im = cv2.imread(im_path)\n",
    "    if im is not None:\n",
    "        out_file = './Data/Test_offline_cleaned/'+im_path[im_path.rfind('/')+1:im_path.rfind('.')]+'.jpg'\n",
    "        if not os.path.exists(out_file):\n",
    "            im = extractTshirt(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "            cv2.imwrite(out_file, cv2.cvtColor(im, cv2.COLOR_RGB2BGR))\n",
    "            dims_test.append(im.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.get_dummies(train['Sub_category'])\n",
    "labels.index = train.Link_to_the_image.astype(str).map(lambda x : x[x.rfind('/')+1:x.rfind('.')]+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_files = glob.glob('./Data/Test_offline_cleaned/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "width = 75\n",
    "height = 75\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14701/14701 [03:39<00:00, 66.92it/s]\n"
     ]
    }
   ],
   "source": [
    "x_im_test = np.empty((len(test_files), height, width, channels))\n",
    "link_test = []\n",
    "for idx, im_path in enumerate(tqdm(test_files)):\n",
    "    im = cv2.cvtColor(cv2.imread(im_path), cv2.COLOR_BGR2RGB)\n",
    "    im = cv2.resize(im, (width, height), interpolation=cv2.INTER_AREA).reshape((height, width, channels))\n",
    "    im_path = im_path[im_path.rfind('/')+1:]\n",
    "    x_im_test[idx] = im\n",
    "    link_test.append(im_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('./Data/test_data_offline.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"x_im\",  data=x_im_test, maxshape=(None, height, width, channels))\n",
    "pickle.dump(link_test, open('./Data/test_data_offline_links.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('./Data/test_data_offline.h5', 'r') as hf:\n",
    "    x_im_test = hf['x_im'][:]/255.0\n",
    "link_test = pickle.load(open('./Data/test_data_offline_links.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = x_im_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    input_ = Input(shape=(height, width, channels), name=\"X_1\")\n",
    "    \n",
    "    # Layers 1+2\n",
    "    out = Conv2D(9, (3, 3), padding='valid')(input_)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = Conv2D(18, (3, 3), padding='valid')(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = MaxPooling2D((2, 2), strides=(2, 2))(out)\n",
    "    out = Dropout(0.1)(out)\n",
    "    \n",
    "    # Layers 2+3\n",
    "    out = Conv2D(36, (3, 3), padding='valid')(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = Conv2D(72, (3, 3), padding='valid')(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = MaxPooling2D((2, 2), strides=(2, 2))(out)\n",
    "#     out = Dropout(0.1)(out)\n",
    "\n",
    "    # Layer 4\n",
    "    out = Conv2D(144, (2, 2), padding='valid')(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = MaxPooling2D((2, 2), strides=(2, 2))(out)\n",
    "#     out = Dropout(0.1)(out)\n",
    "    \n",
    "    # Layer 5\n",
    "    out = Conv2D(256, (2, 2), padding='valid')(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = MaxPooling2D((2, 2), strides=(2, 2))(out)\n",
    "#     out = Dropout(0.1)(out)\n",
    "    \n",
    "    out = Flatten()(out)\n",
    "    \n",
    "    # FCs 1+2+3\n",
    "    out = Dense(1024, activation='relu')(out)\n",
    "    out = Dropout(0.5)(out)\n",
    "    out = Dense(196, activation='relu')(out)\n",
    "    out = Dropout(0.1)(out)\n",
    "    out = Dense(24, activation=\"softmax\")(out)\n",
    "\n",
    "    model = Model(input_, out)\n",
    "    optimizer = Adam()\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = 5\n",
    "kfold_scores = []\n",
    "\n",
    "results = []\n",
    "sss = KFold(n_splits=kfold, random_state=0)\n",
    "for i in range(5):\n",
    "    \n",
    "    model.load_weights('keras_models/kfold_w_arms_col/best_weights_'+str(i+1)+'.hdf5')\n",
    "\n",
    "    # Predict\n",
    "    preds_test = model.predict(x_test)    \n",
    "    results.append(preds_test)\n",
    "    \n",
    "label_list = list(labels.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_list = list(labels.columns)\n",
    "label_map_dict= {i.lower() : i for i in label_list}\n",
    "combined_results = np.argmax(np.array(results).mean(axis=0), 1)\n",
    "combined_results = [label_list[i] for i in combined_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = set([i.lower() for i in labels.columns])\n",
    "test['leakage_labs'] = test.Link_to_the_image.astype(str).map(lambda x :\n",
    "                                                      list(set(x[x.rfind('/')+1:x.rfind('.')].lower() \\\n",
    "                                                      .split('-')).intersection(b)))\n",
    "test['leakage_labs'] = test['leakage_labs'].map(lambda x : label_map_dict[x[0]] if len(x) > 0 else np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['Key'] = test.Link_to_the_image.astype(str).map(lambda x : x[x.rfind('/')+1:x.rfind('.')]+'.jpg')\n",
    "test['prediction'] = test['Key'].map(lambda x : combined_results[link_test.index(x)] \n",
    "                                     if x in link_test else '')\n",
    "test['Sub_category'] = test['leakage_labs'].fillna(test['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test.drop(['Key', 'leakage_labs', 'prediction'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test.fillna('')\n",
    "test.to_csv('./Submissions/Sub_offline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abstract': 251,\n",
       " 'Biker': 4,\n",
       " 'Camouflage': 27,\n",
       " 'Checked': 21,\n",
       " 'Colourblocked': 462,\n",
       " 'Conversational': 151,\n",
       " 'Floral': 289,\n",
       " 'Geometric': 278,\n",
       " 'Graphic': 1171,\n",
       " 'Humour and Comic': 48,\n",
       " 'People and Places': 125,\n",
       " 'Self Design': 4,\n",
       " 'Solid': 5814,\n",
       " 'Sports': 1,\n",
       " 'Sports and Team Jersey': 3,\n",
       " 'Striped': 2337,\n",
       " 'Superhero': 79,\n",
       " 'Tribal': 1,\n",
       " 'Typography': 3616,\n",
       " 'Varsity': 19}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{x:combined_results.count(x) for x in combined_results}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepLearn]",
   "language": "python",
   "name": "conda-env-deepLearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
